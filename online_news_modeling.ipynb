{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression,mutual_info_regression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dropped_news_df_model', 'rb') as handle:\n",
    "    dropped_news = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>num_videos</th>\n",
       "      <th>average_token_length</th>\n",
       "      <th>num_keywords</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>shares</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>LDA</th>\n",
       "      <th>lda</th>\n",
       "      <th>channels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>4.680365</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>593</td>\n",
       "      <td>Monday</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>4.913725</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118750</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>711</td>\n",
       "      <td>Monday</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>4.393365</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1500</td>\n",
       "      <td>Monday</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>531.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>4.404896</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.369697</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1200</td>\n",
       "      <td>Monday</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>4.682836</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.220192</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>505</td>\n",
       "      <td>Monday</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>Tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_tokens_title  n_tokens_content  n_non_stop_words  num_hrefs  \\\n",
       "0            12.0             219.0               1.0        4.0   \n",
       "1             9.0             255.0               1.0        3.0   \n",
       "2             9.0             211.0               1.0        3.0   \n",
       "3             9.0             531.0               1.0        9.0   \n",
       "4            13.0            1072.0               1.0       19.0   \n",
       "\n",
       "   num_self_hrefs  num_imgs  num_videos  average_token_length  num_keywords  \\\n",
       "0        2.000000       1.0    0.000001              4.680365           5.0   \n",
       "1        1.000000       1.0    0.000001              4.913725           4.0   \n",
       "2        1.000000       1.0    0.000001              4.393365           6.0   \n",
       "3        0.000001       1.0    0.000001              4.404896           7.0   \n",
       "4       19.000000      20.0    0.000001              4.682836           7.0   \n",
       "\n",
       "   data_channel_is_entertainment  ...  avg_negative_polarity  \\\n",
       "0                       1.000000  ...              -0.350000   \n",
       "1                       0.000001  ...              -0.118750   \n",
       "2                       0.000001  ...              -0.466667   \n",
       "3                       1.000000  ...              -0.369697   \n",
       "4                       0.000001  ...              -0.220192   \n",
       "\n",
       "   title_subjectivity  title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0            0.500000                 -0.187500                0.000001   \n",
       "1            0.000001                  0.000001                0.500000   \n",
       "2            0.000001                  0.000001                0.500000   \n",
       "3            0.000001                  0.000001                0.500000   \n",
       "4            0.454545                  0.136364                0.045455   \n",
       "\n",
       "   abs_title_sentiment_polarity  shares  day_of_week  LDA  lda       channels  \n",
       "0                      0.187500     593       Monday  nan  nan  Entertainment  \n",
       "1                      0.000001     711       Monday  nan  nan       Business  \n",
       "2                      0.000001    1500       Monday  nan  nan       Business  \n",
       "3                      0.000001    1200       Monday  nan  nan  Entertainment  \n",
       "4                      0.136364     505       Monday  nan  nan           Tech  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropped_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping Columns that I Made for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_news.drop(columns=['day_of_week', 'LDA', 'lda', 'channels'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Target and Feature Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.log(dropped_news['shares'])\n",
    "features = dropped_news.drop(columns='shares')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making All 0 Values into 0.000000001 Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_news.replace(to_replace=0, value=0.000001, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up Train/Test Split with Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=23,test_size=0.2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly= PolynomialFeatures(degree=2, include_bias=False) # if you only want interactions without any squared features add interaction_only=True\n",
    "poly_train=poly.fit_transform(X_train)\n",
    "poly_test= poly.transform(X_test) # Not sure if this should be fit_transform or just transform\n",
    "poly_cols=poly.get_feature_names(X_train.columns)\n",
    "poly_cols=[col.replace(' ','X') for col in poly_cols]\n",
    "X_train_poly=pd.DataFrame(data=poly_train,columns=poly_cols)\n",
    "X_test_poly=pd.DataFrame(data=poly_test,columns=poly_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Data using Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_poly)\n",
    "X_train_poly = pd.DataFrame(data=scaler.transform(X_train_poly), columns=X_train_poly.columns)\n",
    "X_test_poly =pd.DataFrame(data=scaler.transform(X_test_poly), columns=X_train_poly.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Data Using MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train_poly)\n",
    "X_train_poly = pd.DataFrame(data=scaler.transform(X_train_poly), columns=X_train_poly.columns)\n",
    "X_test_poly =pd.DataFrame(data=scaler.transform(X_test_poly), columns=X_train_poly.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### I seem to be getting similar results with both a MinMax Scaler and a Standard Scaler after creating polynomial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Root Mean Squared Error: 2.3380910489678985\n",
      "Testing Root Mean Squared Error: 2.402830037486477\n",
      "Training R^2:  0.15754910876183226 Testing R^2:  0.1036408432220336\n"
     ]
    }
   ],
   "source": [
    "#instantiate a linear regression object\n",
    "lm = LinearRegression(normalize=True)\n",
    "\n",
    "#fit the linear regression to the data\n",
    "lm = lm.fit(X_train_poly, y_train)\n",
    "\n",
    "y_train_pred = (lm.predict(X_train_poly))\n",
    "\n",
    "train_rmse = (np.sqrt(metrics.mean_squared_error((y_train), y_train_pred)))\n",
    "train_rmse = np.exp(train_rmse)\n",
    "\n",
    "print('Training Root Mean Squared Error:' , train_rmse)\n",
    "\n",
    "y_test_pred = (lm.predict(X_test_poly))\n",
    "\n",
    "test_rmse = np.sqrt(metrics.mean_squared_error((y_test), y_test_pred))\n",
    "test_rmse = np.exp(test_rmse)\n",
    "# r_square = metrics.r2_score(y_train_pred, y_pred)\n",
    "\n",
    "print('Testing Root Mean Squared Error:' , test_rmse)\n",
    "\n",
    "\n",
    "print('Training R^2: ', float(metrics.r2_score(y_train, y_train_pred)), 'Testing R^2: ', float(metrics.r2_score(y_test, y_test_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(y_train, y_train_pred,lowess=True, color=\"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00020180367253950897"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rmse / dropped_news.shares.std()\n",
    "# normalized training rmse for standard regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00020739137864928998"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rmse/dropped_news.shares.std()\n",
    "# normalized test rmse for standard regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-Test Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selector = SelectKBest(f_regression, k=10)\n",
    "# selector.fit(X_train_poly, y_train)\n",
    "# selected_ftest = X_train_poly.columns[selector.get_support()]\n",
    "# removed_ftest = X_train_poly.columns[~selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #instantiate a linear regression object\n",
    "# lm_ftest = LinearRegression()\n",
    "\n",
    "# #fit the linear regression to the data\n",
    "# lm_ftest = lm_ftest.fit(X_train_poly[selected_ftest], y_train)\n",
    "\n",
    "# y_train_pred_ftest = (lm_ftest.predict((X_train_poly[selected_ftest])))\n",
    "\n",
    "# train_rmse_ftest = (np.sqrt(metrics.mean_squared_error((y_train), y_train_pred_ftest)))\n",
    "# train_rmse_ftest = np.exp(train_rmse_ftest)\n",
    "\n",
    "\n",
    "# print('Training Root Mean Squared Error:' , train_rmse_ftest)\n",
    "\n",
    "# y_pred_ftest = (lm_ftest.predict((X_test_poly[selected_ftest])))\n",
    "\n",
    "# test_rmse_ftest = np.sqrt(metrics.mean_squared_error((y_test), y_pred_ftest))\n",
    "# test_rmse_ftest = np.exp(test_rmse_ftest)\n",
    "\n",
    "# print('Testing Root Mean Squared Error:' , test_rmse_ftest)\n",
    "\n",
    "\n",
    "# print(\"vs. Testing: \", float(test_rmse),\n",
    "#       \"vs. Testing ftest: \", float(test_rmse_ftest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### the f-test model took too long to run (I let it sit for an hour and a half | also after changing the cv) without returning a result, so I decided not to use it. I included it to show that I attempted to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Feature Elimination Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ols = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-f1114bf4e19e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fit recursive feature eliminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    520\u001b[0m         scores = parallel(\n\u001b[1;32m    521\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m             for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    520\u001b[0m         scores = parallel(\n\u001b[1;32m    521\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m             for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36m_rfe_single_fit\u001b[0;34m(rfe, estimator, X, y, train, test, scorer)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     return rfe._fit(\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         _score(estimator, X_test[:, features], y_test, scorer)).scores_\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fitting estimator with %d features.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;31m# Get coefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_residues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingular_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m                 \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/linalg/basic.py\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(a, b, cond, overwrite_a, overwrite_b, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m   1209\u001b[0m                 \u001b[0mlwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compute_lwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlapack_lwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m                 x, s, rank, info = lapack_func(a1, b1, lwork,\n\u001b[0;32m-> 1211\u001b[0;31m                                                iwork, cond, False, False)\n\u001b[0m\u001b[1;32m   1212\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# complex data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m                 lwork, rwork, iwork = _compute_lwork(lapack_lwork, m, n,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Create recursive feature eliminator that scores features by mean squared errors\n",
    "# selector = RFECV(estimator=ols, step=1, cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "# # Fit recursive feature eliminator \n",
    "# selector.fit(X_train_poly, y_train)\n",
    "# selected_rfe = X_train.columns[selector.support_]\n",
    "# removed_rfe = X_train.columns[~selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #instantiate a linear regression object\n",
    "# lm_rfe = LinearRegression()\n",
    "\n",
    "# #fit the linear regression to the data\n",
    "# lm_rfe = lm_rfe.fit(X_train[selected_rfe], y_train)\n",
    "\n",
    "# y_train_pred_rfe = np.exp(lm_rfe.predict(X_train[selected_rfe]))\n",
    "\n",
    "# train_rmse_rfe = np.sqrt(metrics.mean_squared_error((y_train), y_train_pred_rfe))\n",
    "\n",
    "\n",
    "# print('Training Root Mean Squared Error:' , train_rmse_rfe)\n",
    "\n",
    "# y_pred_rfe = np.exp(lm_rfe.predict(X_test[selected_rfe]))\n",
    "\n",
    "# test_rmse_rfe = np.sqrt(metrics.mean_squared_error((y_test), y_pred_rfe))\n",
    "\n",
    "# print('Testing Root Mean Squared Error:' , test_rmse_rfe)\n",
    "\n",
    "\n",
    "# print(\"vs. Testing: \", float(test_rmse), \n",
    "#       \"vs. Testing rfe: \", float(test_rmse_rfe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### I ran into a similar issue with the RFE model as I did with the F-Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error: 1773.6016889271045\n",
      "Testing Error: 1805.9040898910057\n",
      "Training R^2:  0.0726976829820336 Testing R^2:  0.07024109951847812\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.05, max_iter = 5000, normalize=False)\n",
    "\n",
    "final_lasso = lasso.fit(X_train_poly,y_train)\n",
    "\n",
    "y_train_pred_las = np.exp(lasso.predict(X_train_poly))\n",
    "y_test_pred_las = np.exp(lasso.predict(X_test_poly))\n",
    "\n",
    "train_rmse_las = (metrics.mean_absolute_error(y_train, y_train_pred_las))\n",
    "# train_rmse_las = np.exp(train_rmse_las)\n",
    "\n",
    "test_rmse_las = np.sqrt(metrics.mean_squared_error(y_test, y_test_pred_las))\n",
    "# test_rmse_las = np.exp(test_rmse_las)\n",
    "\n",
    "\n",
    "print('Training Error: '+ str(train_rmse_las))\n",
    "print('Testing Error: '+ str(test_rmse_las))\n",
    "print('Training R^2: ', float(metrics.r2_score(y_train, np.log(y_train_pred_las))), 'Testing R^2: ', float(metrics.r2_score(y_test, np.log(y_test_pred_las))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(y_train, y_train_pred_las,lowess=True, color=\"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15308186334563895"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rmse_las/dropped_news.shares.std()\n",
    "# normalized training rmse for lasso regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15586992549113862"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rmse_las/dropped_news.shares.std()\n",
    "# normalized test rmse for lasso regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error: 0.8518884132867331\n",
      "Testing Error: 0.878059514893663\n",
      "Training R^2:  0.15247567184666022 Testing R^2:  0.10075042460807959\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=0.05, max_iter = 5000, normalize=False)\n",
    "\n",
    "final_ridge = ridge.fit(X_train_poly, y_train)\n",
    "\n",
    "y_train_pred_rid = ridge.predict(X_train_poly)\n",
    "y_test_pred_rid = ridge.predict(X_test_poly)\n",
    "\n",
    "train_rmse_rid = (np.sqrt(metrics.mean_squared_error(y_train,y_train_pred_rid)))\n",
    "test_rmse_rid = (np.sqrt(metrics.mean_squared_error(y_test, y_test_pred_rid)))\n",
    "\n",
    "print('Training Error: '+ str(train_rmse_rid))\n",
    "print('Testing Error: '+ str(test_rmse_rid))\n",
    "print('Training R^2: ', float(metrics.r2_score(y_train, y_train_pred_rid)), 'Testing R^2: ', float(metrics.r2_score(y_test, y_test_pred_rid)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(y_train, y_train_pred_rid,lowess=True, color=\"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.352759443264868e-05"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_rmse_rid/dropped_news.shares.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.578645617415976e-05"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rmse_rid/dropped_news.shares.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
