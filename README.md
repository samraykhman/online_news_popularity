# online_news_popularity

The original goal of the project was to be able to predict the amount of shares that an article on Mashable would receive, with the use of around 60 variables. However, after playing with my data and trying to set up feature columns (which required me to make interaction terms among the features, resulting in just under 800 columns), my goal has changed to "being able to explain the data and maybe predict the amount of shares that an article might get given certain conditions." For my project, I collected my dataset from the UCI Machine Learning Repository and I needed to use pandas to clean my data, seaborn to visualize certain independent variables in relationship to my dependent variable (shares), and scikit-learn to build the regression/prediction models. On GitHub, you will find thre Jupyter Notebooks with my code for cleaning/exploratory data analysis, statistical analysis, and modeling; a csv file of the dataset that I used from the UCI Machine Learning Repository; several pickled files of the dataframe I created so I could use it between notebooks; and a PDF of my presentation of slides with my final explanations. The data I used consisted of 61 attributes and 39,797 instances.

From the data I can declare that ...... was statistically significant and has an affect on the number of shares received.

If I had more time, I would have liked to use my K-Best/F-Test and Recursive Feature Elimination models. Unfortunately, they were taking too much time to run and I did not have enough time to let them completely run their course. 